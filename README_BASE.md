# awesome-fast-attention [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

A curated list of efficient attention modules (last update: {{{generation-date}}})

## Table of Contents

* **[Efficient Attention](#efficient-attention)**
* **[Articles](#articles)**

## Efficient Attention

{{{fast-attention-table}}}

## Articles

* [A Survey of Long-Term Context in Transformers](https://www.pragmatic.ml/a-survey-of-methods-for-incorporating-long-term-context/)

